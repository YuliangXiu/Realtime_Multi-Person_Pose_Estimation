{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from scipy.io import loadmat, savemat\n",
    "import PIL.Image\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import math\n",
    "import caffe\n",
    "import time\n",
    "from config_reader import config_reader\n",
    "import util\n",
    "import copy\n",
    "import os\n",
    "from itertools import compress\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drawing parameters\n",
    "mat_path = \"/home/yuliang/data/MultiPerson_PoseTrack_v0.1/MultiPerson_PoseTrack_v0.1.mat\"\n",
    "bonn_mat = loadmat(mat_path)['RELEASE']\n",
    "is_train = bonn_mat['is_train'][0,0]\n",
    "\n",
    "video_names = [video_name[0][0] for video_name in bonn_mat['annolist'][0,0]['name']]\n",
    "video_frames = [video_frame[0][0] for video_frame in bonn_mat['annolist'][0,0]['num_frames']]\n",
    "\n",
    "train_names = list(compress(video_names[:], is_train))\n",
    "test_names = [x for x in video_names if x not in train_names]\n",
    "\n",
    "train_frames = [item[0] for item in list(compress(video_frames[:], is_train))]\n",
    "test_frames = [item[0] for item in list(compress(video_frames[:], 1-is_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8348c2c0ac5d4aa9ae8d039f7da71862"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param, model = config_reader()\n",
    "root_dir = \"/home/yuliang/data/MultiPerson_PoseTrack_v0.1/videos/\"\n",
    "image_x, image_y, image_channel = cv.imread(os.path.join(root_dir,'000002','00001.jpg')).shape\n",
    "\n",
    "oriImgs = dict()\n",
    "multiplier = dict()\n",
    "\n",
    "for vid, test_name in enumerate(tqdm_notebook(test_names)):\n",
    "    oriImgs[test_name] = dict()\n",
    "    for frame_name in ['{:0>5}.jpg'.format(frame+1) for frame in range(test_frames[vid])]:\n",
    "        oriImgs[test_name][frame_name] = cv.imread(os.path.join(root_dir,test_name,frame_name))\n",
    "        image_x, image_y, channel = oriImgs[test_name][frame_name].shape\n",
    "        multiplier[test_name] = [x * model['boxsize'] /image_x for x in param['scale_search']]\n",
    "\n",
    "np.save('npy/oriImgs.npy',oriImgs) \n",
    "np.save('npy/multiplier.npy',multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if param['use_gpu']: \n",
    "    caffe.set_mode_gpu()\n",
    "    caffe.set_device(param['GPUdeviceNumber']) # set to your device!\n",
    "else:\n",
    "    caffe.set_mode_cpu()\n",
    "net = caffe.Net(model['deployFile'], model['caffemodel'], caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1fc88949d44c41a7f7d694b2324fc8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = dict()\n",
    "paf = dict()\n",
    "\n",
    "part = 18  # all parts\n",
    "\n",
    "for vid, test_name in enumerate(tqdm_notebook(test_names)):\n",
    "\n",
    "    heatmap[test_name] = dict()\n",
    "    paf[test_name] = dict()\n",
    "    for fid, frame_name in enumerate(['{:0>5}.jpg'.format(frame+1) for frame in range(test_frames[vid])]):\n",
    "        image_x, image_y, channel = oriImgs[test_name][frame_name].shape\n",
    "        heatmap[test_name][frame_name] = dict()\n",
    "        paf[test_name][frame_name] = dict()\n",
    "\n",
    "        heatmap[test_name][frame_name]['heatmap_avg'] = np.zeros((image_x, image_y, 19))\n",
    "        paf[test_name][frame_name]['paf_avg'] = np.zeros((image_x, image_y, 38))\n",
    "        for m in range(len(multiplier[test_name])):\n",
    "            scale = multiplier[test_name][m]\n",
    "            heatmap[test_name][frame_name][scale] = dict()\n",
    "            paf[test_name][frame_name][scale] = dict()\n",
    "\n",
    "            imageToTest = cv.resize(oriImgs[test_name][frame_name], (0,0), fx=scale, fy=scale, interpolation=cv.INTER_CUBIC)\n",
    "            imageToTest_padded, pad = util.padRightDownCorner(imageToTest, model['stride'], model['padValue'])\n",
    "\n",
    "            net.blobs['data'].reshape(*(1, 3, imageToTest_padded.shape[0], imageToTest_padded.shape[1]))\n",
    "            net.blobs['data'].data[...] = np.transpose(np.float32(imageToTest_padded[:,:,:,np.newaxis]), (3,2,0,1))/256 - 0.5;\n",
    "            output_blobs = net.forward()\n",
    "\n",
    "            # extract outputs, resize, and remove padding\n",
    "            heatmap_ = np.transpose(np.squeeze(net.blobs[output_blobs.keys()[1]].data), (1,2,0)) # output 1 is heatmaps\n",
    "            heatmap_ = cv.resize(heatmap_, (0,0), fx=model['stride'], fy=model['stride'], interpolation=cv.INTER_CUBIC)\n",
    "            heatmap_ = heatmap_[:imageToTest_padded.shape[0]-pad[2], :imageToTest_padded.shape[1]-pad[3], :]\n",
    "            heatmap[test_name][frame_name][scale] = cv.resize(heatmap_, (image_y, image_x), interpolation=cv.INTER_CUBIC)\n",
    "            heatmap[test_name][frame_name]['heatmap_avg'] = heatmap[test_name][frame_name]['heatmap_avg'] + heatmap[test_name][frame_name][scale] / len(multiplier[test_name])\n",
    "\n",
    "            # extract pad        \n",
    "            paf_ = np.transpose(np.squeeze(net.blobs[output_blobs.keys()[0]].data), (1,2,0)) # output 0 is PAFs\n",
    "            paf_ = cv.resize(paf_, (0,0), fx=model['stride'], fy=model['stride'], interpolation=cv.INTER_CUBIC)\n",
    "            paf_ = paf_[:imageToTest_padded.shape[0]-pad[2], :imageToTest_padded.shape[1]-pad[3], :]\n",
    "            paf[test_name][frame_name][scale] = cv.resize(paf_, (image_y, image_x), interpolation=cv.INTER_CUBIC)\n",
    "            paf[test_name][frame_name]['paf_avg'] = paf[test_name][frame_name]['paf_avg'] + paf[test_name][frame_name][scale] / len(multiplier[test_name])\n",
    "\n",
    "    np.save('npy/'+test_name+'_heatmap.npy', heatmap[test_name])\n",
    "    np.save('npy/'+test_name+'_paf.npy', paf[test_name])\n",
    "    heatmap[test_name] = dict()\n",
    "    paf[test_name] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83bd3bc44324b87a09357e3e79f9cfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "all_peaks = dict()\n",
    "peak_counter = dict()\n",
    "\n",
    "for vid, test_name in enumerate(tqdm_notebook(test_names)):\n",
    "    all_peaks[test_name] = dict()\n",
    "    peak_counter[test_name] = dict()\n",
    "    heatmap[test_name] = np.load('npy/'+test_name+'_heatmap.npy')[()]\n",
    "    for fid, frame_name in enumerate(['{:0>5}.jpg'.format(frame+1) for frame in range(test_frames[vid])]):\n",
    "        all_peaks[test_name][frame_name] = []\n",
    "        peak_counter[test_name][frame_name] = 0\n",
    "        for part in range(18):\n",
    "            x_list = []\n",
    "            y_list = []\n",
    "            map_ori = heatmap[test_name][frame_name]['heatmap_avg'][:,:,part]\n",
    "            map = gaussian_filter(map_ori, sigma=3)\n",
    "\n",
    "            map_left = np.zeros(map.shape)\n",
    "            map_left[1:,:] = map[:-1,:]\n",
    "            map_right = np.zeros(map.shape)\n",
    "            map_right[:-1,:] = map[1:,:]\n",
    "            map_up = np.zeros(map.shape)\n",
    "            map_up[:,1:] = map[:,:-1]\n",
    "            map_down = np.zeros(map.shape)\n",
    "            map_down[:,:-1] = map[:,1:]\n",
    "\n",
    "            peaks_binary = np.logical_and.reduce((map>=map_left, map>=map_right, map>=map_up, map>=map_down, map > param['thre1']))\n",
    "            peaks = zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0]) # note reverse\n",
    "            peaks_with_score = [x + (map_ori[x[1],x[0]],) for x in peaks]\n",
    "            id = range(peak_counter[test_name][frame_name], peak_counter[test_name][frame_name] + len(peaks))\n",
    "            peaks_with_score_and_id = [peaks_with_score[i] + (id[i],) for i in range(len(id))]\n",
    "\n",
    "            all_peaks[test_name][frame_name].append(peaks_with_score_and_id)\n",
    "            peak_counter[test_name][frame_name] += len(peaks)\n",
    "    heatmap[test_name] = dict()\n",
    "\n",
    "np.save('npy/all_peaks.npy', all_peaks)\n",
    "np.save('npy/peak_counter.npy',peak_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find connection in the specified sequence, center 29 is in the position 15\n",
    "limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
    "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
    "           [1,16], [16,18], [3,17], [6,18]]\n",
    "# the middle joints heatmap correpondence\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], [19,20], [21,22], \\\n",
    "          [23,24], [25,26], [27,28], [29,30], [47,48], [49,50], [53,54], [51,52], \\\n",
    "          [55,56], [37,38], [45,46]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print test_names.index('000002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbfd56c36d3492c9d05a3cbb8cc0baa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuliang/.pyenv/versions/2.7.13/envs/env2.7/lib/python2.7/site-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "/home/yuliang/.pyenv/versions/2.7.13/envs/env2.7/lib/python2.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "connection_all = dict()\n",
    "special_k = dict()\n",
    "mid_num = 10\n",
    "\n",
    "for vid, test_name in enumerate(tqdm_notebook(test_names)):\n",
    "    paf[test_name] = dict()\n",
    "    paf[test_name] = np.load('npy/'+test_name+'_paf.npy')[()]\n",
    "    connection_all[test_name] = dict()\n",
    "    special_k[test_name] = dict()\n",
    "    for fid, frame_name in enumerate(['{:0>5}.jpg'.format(frame+1) for frame in range(test_frames[vid])]):\n",
    "        connection_all[test_name][frame_name] = []\n",
    "        special_k[test_name][frame_name] = []\n",
    "        image_x, image_y, channel = oriImgs[test_name][frame_name].shape\n",
    "\n",
    "        for k in range(len(mapIdx)):\n",
    "            score_mid = paf[test_name][frame_name]['paf_avg'][:,:,[x-19 for x in mapIdx[k]]]\n",
    "            candA = all_peaks[test_name][frame_name][limbSeq[k][0]-1]\n",
    "            candB = all_peaks[test_name][frame_name][limbSeq[k][1]-1]\n",
    "            nA = len(candA)\n",
    "            nB = len(candB)\n",
    "            indexA, indexB = limbSeq[k]\n",
    "            if(nA != 0 and nB != 0):\n",
    "                connection_candidate = []\n",
    "                for i in range(nA):\n",
    "                    for j in range(nB):\n",
    "                        vec = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                        norm = math.sqrt(vec[0]*vec[0] + vec[1]*vec[1])\n",
    "                        vec = np.divide(vec, norm)\n",
    "\n",
    "                        startend = zip(np.linspace(candA[i][0], candB[j][0], num=mid_num), \\\n",
    "                                       np.linspace(candA[i][1], candB[j][1], num=mid_num))\n",
    "\n",
    "                        vec_x = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 0] \\\n",
    "                                          for I in range(len(startend))])\n",
    "                        vec_y = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 1] \\\n",
    "                                          for I in range(len(startend))])\n",
    "\n",
    "                        score_midpts = np.multiply(vec_x, vec[0]) + np.multiply(vec_y, vec[1])\n",
    "                        score_with_dist_prior = sum(score_midpts)/len(score_midpts) + min(0.5*image_x/(norm+0.001)-1, 0)\n",
    "                        criterion1 = len(np.nonzero(score_midpts > param['thre2'])[0]) > 0.8 * len(score_midpts)\n",
    "                        criterion2 = score_with_dist_prior > 0\n",
    "                        if criterion1 and criterion2:\n",
    "                            connection_candidate.append([i, j, score_with_dist_prior, score_with_dist_prior+candA[i][2]+candB[j][2]])\n",
    "\n",
    "                connection_candidate = sorted(connection_candidate, key=lambda x: x[2], reverse=True)\n",
    "                connection = np.zeros((0,5))\n",
    "                for c in range(len(connection_candidate)):\n",
    "                    i,j,s = connection_candidate[c][0:3]\n",
    "                    if(i not in connection[:,3] and j not in connection[:,4]):\n",
    "                        connection = np.vstack([connection, [candA[i][3], candB[j][3], s, i, j]])\n",
    "                        if(len(connection) >= min(nA, nB)):\n",
    "                            break\n",
    "\n",
    "                connection_all[test_name][frame_name].append(connection)\n",
    "            else:\n",
    "                special_k[test_name][frame_name].append(k)\n",
    "                connection_all[test_name][frame_name].append([])\n",
    "    paf[test_name] = dict()\n",
    "np.save('npy/connection_all.npy',connection_all)\n",
    "np.save('npy/special_k.npy',special_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15d22e1af9946a38f036db86082d507"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# last number in each row is the total parts number of that person\n",
    "# the second last number in each row is the score of the overall configuration\n",
    "subset = dict()\n",
    "candidate = dict()\n",
    "for vid, test_name in enumerate(tqdm_notebook(test_names)):\n",
    "    candidate[test_name] = dict()\n",
    "    subset[test_name] = dict()\n",
    "    for fid, frame_name in enumerate(['{:0>5}.jpg'.format(frame+1) for frame in range(test_frames[vid])]):\n",
    "        image_x, image_y, channel = oriImgs[test_name][frame_name].shape\n",
    "        candidate[test_name][frame_name] = np.array([item for sublist in all_peaks[test_name][frame_name] for item in sublist])\n",
    "        subset[test_name][frame_name] = -1 * np.ones(( 0, 20))\n",
    "        for k in range(len(mapIdx)):\n",
    "            if k not in special_k[test_name][frame_name]:\n",
    "                partAs = connection_all[test_name][frame_name][k][:,0]\n",
    "                partBs = connection_all[test_name][frame_name][k][:,1]\n",
    "                indexA, indexB = np.array(limbSeq[k]) - 1\n",
    "                for i in range(len(connection_all[test_name][frame_name][k])): #= 1:size(temp,1)\n",
    "                    found = 0\n",
    "                    subset_idx = [-1, -1]\n",
    "                    for j in range(len(subset[test_name][frame_name])): #1:size(subset,1):\n",
    "                        if subset[test_name][frame_name][j][indexA] == partAs[i] or subset[test_name][frame_name][j][indexB] == partBs[i]:\n",
    "                            subset_idx[found] = j\n",
    "                            found += 1\n",
    "\n",
    "                    if found == 1:\n",
    "                        j = subset_idx[0]\n",
    "                        if(subset[test_name][frame_name][j][indexB] != partBs[i]):\n",
    "                            subset[test_name][frame_name][j][indexB] = partBs[i]\n",
    "                            subset[test_name][frame_name][j][-1] += 1\n",
    "                            subset[test_name][frame_name][j][-2] += candidate[test_name][frame_name][partBs[i].astype(int), 2] + connection_all[test_name][frame_name][k][i][2]\n",
    "                    elif found == 2: # if found 2 and disjoint, merge them\n",
    "                        j1, j2 = subset_idx\n",
    "#                         print \"found = 2\"\n",
    "                        membership = ((subset[test_name][frame_name][j1]>=0).astype(int) + (subset[test_name][frame_name][j2]>=0).astype(int))[:-2]\n",
    "                        if len(np.nonzero(membership == 2)[0]) == 0: #merge\n",
    "                            subset[test_name][frame_name][j1][:-2] += (subset[test_name][frame_name][j2][:-2] + 1)\n",
    "                            subset[test_name][frame_name][j1][-2:] += subset[test_name][frame_name][j2][-2:]\n",
    "                            subset[test_name][frame_name][j1][-2] += connection_all[test_name][frame_name][k][i][2]\n",
    "                            subset[test_name][frame_name] = np.delete(subset[test_name][frame_name], j2, 0)\n",
    "                        else: # as like found == 1\n",
    "                            subset[test_name][frame_name][j1][indexB] = partBs[i]\n",
    "                            subset[test_name][frame_name][j1][-1] += 1\n",
    "                            subset[test_name][frame_name][j1][-2] += candidate[test_name][frame_name][partBs[i].astype(int), 2] + connection_all[test_name][frame_name][k][i][2]\n",
    "\n",
    "                    # if find no partA in the subset, create a new subset\n",
    "                    elif not found and k < 17:\n",
    "                        row = -1 * np.ones(20)\n",
    "                        row[indexA] = partAs[i]\n",
    "                        row[indexB] = partBs[i]\n",
    "                        row[-1] = 2\n",
    "                        row[-2] = sum(candidate[test_name][frame_name][connection_all[test_name][frame_name][k][i,:2].astype(int), 2]) + connection_all[test_name][frame_name][k][i][2]\n",
    "                        subset[test_name][frame_name] = np.vstack([subset[test_name][frame_name], row])\n",
    "np.save('npy/subset.npy', subset)\n",
    "np.save('npy/candidate.npy', candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45f3e7ab2c341ce8ea01de97ce6f508"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# delete some rows of subset which has few parts occur\n",
    "for vid, test_name in enumerate(tqdm_notebook(test_names)):\n",
    "    for fid, frame_name in enumerate(['{:0>5}.jpg'.format(frame+1) for frame in range(test_frames[vid])]):\n",
    "        deleteIdx = [];\n",
    "        for i in range(len(subset[test_name][frame_name])):\n",
    "            if subset[test_name][frame_name][i][-1] < 4 or subset[test_name][frame_name][i][-2]/subset[test_name][frame_name][i][-1] < 0.4:\n",
    "                deleteIdx.append(i)\n",
    "        subset[test_name][frame_name] = np.delete(subset[test_name][frame_name], deleteIdx, axis=0)\n",
    "np.save('npy/subset.npy', subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optical flow \n",
    "all_flow = np.zeros((frame_num, oriImg.shape[1], oriImg.shape[2], 2))\n",
    "\n",
    "# show optical flow\n",
    "f3, axarr3 = plt.subplots(rows_small, cols_small)\n",
    "f3.set_size_inches((width_small, height_small))\n",
    "\n",
    "frame1 = oriImg[0]\n",
    "prvs = cv.cvtColor(frame1,cv.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "for frame in tqdm_notebook(range(1,frame_num)):\n",
    "    frame2 = oriImg[frame]\n",
    "    next = cv.cvtColor(frame2,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    all_flow[frame] = cv.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    mag, ang = cv.cartToPolar(all_flow[frame][...,0], all_flow[frame][...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv.normalize(mag,None,0,255,cv.NORM_MINMAX)\n",
    "    rgb = cv.cvtColor(hsv,cv.COLOR_HSV2BGR)\n",
    "\n",
    "    axarr3[frame/cols_small][frame%cols_small].imshow(rgb)\n",
    "    prvs = next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_peaks = np.load('npy/all_peaks.npy')\n",
    "subset = np.load('npy/subset.npy')\n",
    "candidate = np.load('npy/candidate.npy')\n",
    "connection_all = np.load('npy/connection_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  9.        ,  14.        ,   0.8853993 ,   4.        ,   4.        ],\n",
      "       [  7.        ,  12.        ,   0.8793927 ,   2.        ,   2.        ],\n",
      "       [  6.        ,  11.        ,   0.67850917,   1.        ,   1.        ],\n",
      "       [  8.        ,  13.        ,   0.52986185,   3.        ,   3.        ]]), array([[  7.        ,  26.        ,   0.91293517,   2.        ,   3.        ],\n",
      "       [  9.        ,  27.        ,   0.91087522,   4.        ,   4.        ],\n",
      "       [  6.        ,  24.        ,   0.55530952,   1.        ,   1.        ],\n",
      "       [  8.        ,  25.        ,   0.50080276,   3.        ,   2.        ]]), array([[ 13.        ,  17.        ,   0.9335336 ,   3.        ,   2.        ],\n",
      "       [ 11.        ,  16.        ,   0.92536813,   1.        ,   1.        ],\n",
      "       [ 14.        ,  15.        ,   0.55030392,   4.        ,   0.        ]]), array([[ 17.        ,  18.        ,   0.83552914,   2.        ,   0.        ],\n",
      "       [ 16.        ,  20.        ,   0.72125207,   1.        ,   2.        ],\n",
      "       [ 15.        ,  21.        ,   0.28628573,   0.        ,   3.        ]]), array([[ 27.        ,  29.        ,   0.9619731 ,   4.        ,   1.        ],\n",
      "       [ 26.        ,  30.        ,   0.74686884,   3.        ,   2.        ],\n",
      "       [ 25.        ,  31.        ,   0.33882149,   2.        ,   3.        ],\n",
      "       [ 23.        ,  28.        ,   0.1684539 ,   0.        ,   0.        ]]), array([[ 30.        ,  33.        ,   0.95464024,   2.        ,   1.        ],\n",
      "       [ 29.        ,  36.        ,   0.58165361,   1.        ,   4.        ],\n",
      "       [ 31.        ,  32.        ,   0.13386155,   3.        ,   0.        ]]), array([[  9.        ,  38.        ,   0.79266262,   4.        ,   1.        ],\n",
      "       [  7.        ,  37.        ,   0.64267292,   2.        ,   0.        ],\n",
      "       [  8.        ,  40.        ,   0.4883743 ,   3.        ,   3.        ],\n",
      "       [  6.        ,  39.        ,   0.46691544,   1.        ,   2.        ]]), array([[ 38.        ,  42.        ,   0.72260793,   1.        ,   1.        ],\n",
      "       [ 39.        ,  44.        ,   0.48496004,   2.        ,   3.        ],\n",
      "       [ 40.        ,  43.        ,   0.3273499 ,   3.        ,   2.        ],\n",
      "       [ 37.        ,  41.        ,   0.23483496,   0.        ,   0.        ]]), array([[ 42.        ,  45.        ,   0.77122865,   1.        ,   0.        ]]), array([[  9.        ,  48.        ,   0.89313207,   4.        ,   1.        ],\n",
      "       [  7.        ,  47.        ,   0.75525019,   2.        ,   0.        ],\n",
      "       [  8.        ,  50.        ,   0.45386693,   3.        ,   3.        ],\n",
      "       [  6.        ,  49.        ,   0.42538396,   1.        ,   2.        ]]), array([[ 48.        ,  52.        ,   0.914993  ,   1.        ,   1.        ],\n",
      "       [ 49.        ,  54.        ,   0.37400709,   2.        ,   3.        ],\n",
      "       [ 47.        ,  51.        ,   0.34962046,   0.        ,   0.        ],\n",
      "       [ 50.        ,  55.        ,   0.34622591,   3.        ,   4.        ]]), array([[ 52.        ,  57.        ,   0.81094251,   1.        ,   1.        ],\n",
      "       [ 53.        ,  58.        ,   0.33388214,   2.        ,   2.        ],\n",
      "       [ 51.        ,  56.        ,   0.17086903,   0.        ,   0.        ]]), array([[ 9.        ,  4.        ,  1.02041707,  4.        ,  4.        ],\n",
      "       [ 7.        ,  2.        ,  0.92073698,  2.        ,  2.        ],\n",
      "       [ 6.        ,  1.        ,  0.75760937,  1.        ,  1.        ],\n",
      "       [ 8.        ,  3.        ,  0.66215146,  3.        ,  3.        ],\n",
      "       [ 5.        ,  0.        ,  0.14084187,  0.        ,  0.        ]]), array([[  3.        ,  61.        ,   1.14307147,   3.        ,   2.        ],\n",
      "       [  4.        ,  63.        ,   1.10078243,   4.        ,   4.        ],\n",
      "       [  1.        ,  60.        ,   1.05689875,   1.        ,   1.        ],\n",
      "       [  2.        ,  62.        ,   0.84120387,   2.        ,   3.        ],\n",
      "       [  0.        ,  59.        ,   0.25260341,   0.        ,   0.        ]]), array([[ 60.        ,  69.        ,   1.09617134,   1.        ,   1.        ],\n",
      "       [ 61.        ,  70.        ,   1.03046711,   2.        ,   2.        ],\n",
      "       [ 63.        ,  71.        ,   0.67270515,   4.        ,   3.        ],\n",
      "       [ 59.        ,  68.        ,   0.25812536,   0.        ,   0.        ]]), array([[  2.        ,  66.        ,   0.97191218,   2.        ,   2.        ],\n",
      "       [  4.        ,  67.        ,   0.95054803,   4.        ,   3.        ],\n",
      "       [  3.        ,  65.        ,   0.41484911,   3.        ,   1.        ],\n",
      "       [  1.        ,  64.        ,   0.20620106,   1.        ,   0.        ]]), array([[ 66.        ,  72.        ,   0.98676279,   2.        ,   0.        ],\n",
      "       [ 67.        ,  73.        ,   0.73748246,   3.        ,   1.        ]]), array([[ 13.        ,  70.        ,   0.88298738,   3.        ,   2.        ],\n",
      "       [ 11.        ,  69.        ,   0.84515248,   1.        ,   1.        ],\n",
      "       [ 14.        ,  71.        ,   0.6682398 ,   4.        ,   3.        ],\n",
      "       [ 10.        ,  68.        ,   0.22248562,   0.        ,   0.        ]]), array([[ 26.        ,  72.        ,   0.8386175 ,   3.        ,   0.        ],\n",
      "       [ 27.        ,  73.        ,   0.71571336,   4.        ,   1.        ]])]\n"
     ]
    }
   ],
   "source": [
    "print connection_all[()]['000002']['00001.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
